<!DOCTYPE html>
<html lang="zh-CN"
  dir="ltr">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">








    






<link rel="icon" type="image/ico" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http://localhost:1313/android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/apple-touch-icon.png">

<meta name="description" content="LLM 代码错误画像、修复代价与复杂度分析笔记。"/>



<title>
    
    论文阅读：Towards Understanding the Characteristics of Code Generation Errors Made by Large Language Models | 小郑的自留地
    
</title>

<link rel="canonical" href="http://localhost:1313/garden/2025-07-21-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBtowards-understanding-the-characteristics-of-code-generation-errors-made-by-large-language-models/"/>

<meta property="og:url" content="http://localhost:1313/garden/2025-07-21-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBtowards-understanding-the-characteristics-of-code-generation-errors-made-by-large-language-models/">
  <meta property="og:site_name" content="小郑的自留地">
  <meta property="og:title" content="论文阅读：Towards Understanding the Characteristics of Code Generation Errors Made by Large Language Models">
  <meta property="og:description" content="LLM 代码错误画像、修复代价与复杂度分析笔记。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="garden">
    <meta property="article:published_time" content="2025-07-21T08:00:00+08:00">
    <meta property="article:modified_time" content="2025-07-21T08:00:00+08:00">












<link rel="stylesheet" href="/assets/combined.min.6b8f27efa57c455e68c95c192774db784acb697097a23357a60b96479693bc4e.css" media="all">











    




</head>







<body class="garden-page auto">

  <div class="content">
    

    <main class="main main--garden">
      
        




<div class="garden-layout">
  <aside class="garden-sidebar">
    <section class="garden-sidebar-section">
      <h2 class="garden-sidebar-heading">全部文章</h2>
      <ul class="garden-posts">
        
        
        <li class="garden-posts-item garden-posts-item--home">
          <a class="garden-posts-link garden-posts-link--home " href="/garden/">
            <span class="garden-posts-title">首页</span>
          </a>
        </li>
        
        
        <li class="garden-posts-item">
          <a class="garden-posts-link is-active" href="/garden/2025-07-21-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBtowards-understanding-the-characteristics-of-code-generation-errors-made-by-large-language-models/">
            <span class="garden-posts-title">论文阅读：Towards Understanding the Characteristics of Code Generation Errors Made by Large Language Models</span>
            <time class="garden-posts-date" datetime="2025-07-21">2025-07-21</time>
            
          </a>
        </li>
        
        <li class="garden-posts-item">
          <a class="garden-posts-link " href="/garden/2025-07-09-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBbetween-lines-of-code-unraveling-the-distinct-patterns-of-machine-and-human-programmers/">
            <span class="garden-posts-title">论文阅读：Between Lines of Code——Unraveling the Distinct Patterns of Machine and Human Programmers</span>
            <time class="garden-posts-date" datetime="2025-07-09">2025-07-09</time>
            
          </a>
        </li>
        
      </ul>
    </section>

    <section class="garden-sidebar-section">
      <h2 class="garden-sidebar-heading">目录</h2>
      
      <div class="garden-toc">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#i-introduction">I. Introduction</a></li>
    <li><a href="#ii-methodology">II. Methodology</a>
      <ul>
        <li><a href="#a-研究设计与数据采集">A. 研究设计与数据采集</a></li>
        <li><a href="#b-开放式编码与标签体系构建">B. 开放式编码与标签体系构建</a></li>
        <li><a href="#c-修复代价的度量方式">C. 修复代价的度量方式</a></li>
      </ul>
    </li>
    <li><a href="#iii-results">III. Results</a>
      <ul>
        <li><a href="#a-rq1llm-常犯哪些错误">A. RQ1：LLM 常犯哪些错误？</a></li>
        <li><a href="#b-rq2修复这些错误要多大代价">B. RQ2：修复这些错误要多大代价？</a></li>
        <li><a href="#c-rq3任务复杂度如何影响表现">C. RQ3：任务复杂度如何影响表现？</a></li>
        <li><a href="#d-rq4测试通过率与错误模式">D. RQ4：测试通过率与错误模式</a></li>
      </ul>
    </li>
    <li><a href="#iv-discussion--future-work">IV. Discussion &amp; Future Work</a></li>
    <li><a href="#v-threats-to-validity">V. Threats to Validity</a></li>
  </ul>
</nav>
      </div>
      
    </section>
  </aside>

  <article class="garden-article">
    <a class="garden-back-button" href="/">← 返回博客</a>
    <header class="garden-article-header">
      <h1 class="garden-title">论文阅读：Towards Understanding the Characteristics of Code Generation Errors Made by Large Language Models</h1>
      
      <p class="garden-description">LLM 代码错误画像、修复代价与复杂度分析笔记。</p>
      
    </header>

    <div class="garden-content">
      <p>也是在中大草草阅读的一篇文章，来自 ICSE 25.</p>
<h2 class="heading" id="i-introduction">
  I. Introduction
  <a class="anchor" href="#i-introduction">#</a>
</h2>
<p>作者关注的核心问题是：<strong>大模型到底会犯什么类型的代码错误、这些错误难修到什么程度、与任务复杂度和测试通过率之间又有何关联？</strong> 为此，他们挑选 CodeGen-16B、InCoder-1.3B、GPT-3.5、GPT-4、SantaCoder、StarCoder 六个代表性模型，在 HumanEval 164 个 Python 题目上汇总出了 557 份失败代码，并进行了细粒度的人工标注与分析。</p>
<p>贡献主要有四点：</p>
<ul>
<li>构建了覆盖语义（根因）与句法（位置）两个维度的错误分类法，并在 GitHub 开源了标签及标注结果；</li>
<li>比较了各模型语义/句法错误分布的异同，探索训练数据与错误模式的关系；</li>
<li>定量评估了修复这些错误所需的工作量，并研究任务复杂度与测试通过率对错误分布的影响；</li>
<li>基于标签体系搭建了交互式分析网站，为后续研究者提供可检索的错误案例库。</li>
</ul>
<h2 class="heading" id="ii-methodology">
  II. Methodology
  <a class="anchor" href="#ii-methodology">#</a>
</h2>
<h3 class="heading" id="a-研究设计与数据采集">
  A. 研究设计与数据采集
  <a class="anchor" href="#a-%e7%a0%94%e7%a9%b6%e8%ae%be%e8%ae%a1%e4%b8%8e%e6%95%b0%e6%8d%ae%e9%87%87%e9%9b%86">#</a>
</h3>
<ul>
<li>数据集：HumanEval，共 164 道函数级 Python 编程题，平均 7.7 个单元测试。</li>
<li>提示策略：沿用官方 prompt，温度设为 0 保证可复现性。</li>
<li>错误收集：先跑单元测试过滤失败样本，再人工复核通过测试但语义不等价的情况，额外补充了 19 份隐性错误。</li>
</ul>
<h3 class="heading" id="b-开放式编码与标签体系构建">
  B. 开放式编码与标签体系构建
  <a class="anchor" href="#b-%e5%bc%80%e6%94%be%e5%bc%8f%e7%bc%96%e7%a0%81%e4%b8%8e%e6%a0%87%e7%ad%be%e4%bd%93%e7%b3%bb%e6%9e%84%e5%bb%ba">#</a>
</h3>
<p>两位作者先从 557 份错误代码中随机抽取 160 份进行开放式编码，定位错误片段、记录根因；之后引入另外两位作者共同迭代 codebook。经过三轮 Fleiss&rsquo; κ 校验，最终收敛到 <strong>13 类语义特征 × 14 类句法特征</strong>，全量标注的一致度达到 0.91/0.91。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104009137.png" >
    </div>

    
</figure>
</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104009137.png" >
    </div>

    
</figure>
</p>
<h3 class="heading" id="c-修复代价的度量方式">
  C. 修复代价的度量方式
  <a class="anchor" href="#c-%e4%bf%ae%e5%a4%8d%e4%bb%a3%e4%bb%b7%e7%9a%84%e5%ba%a6%e9%87%8f%e6%96%b9%e5%bc%8f">#</a>
</h3>
<p>作者分别计算：</p>
<ul>
<li><strong>Levenshtein 距离</strong>：字符级最小编辑次数；</li>
<li><strong>Jaccard 相似度</strong>：基于标记集合的重合度；</li>
<li><strong>CodeBERTScore</strong>：利用 CodeBERT 提取语义向量的余弦相似度。</li>
</ul>
<p>所有指标在计算前都会去掉注释，避免非功能性文本干扰。</p>
<h2 class="heading" id="iii-results">
  III. Results
  <a class="anchor" href="#iii-results">#</a>
</h2>
<h3 class="heading" id="a-rq1llm-常犯哪些错误">
  A. RQ1：LLM 常犯哪些错误？
  <a class="anchor" href="#a-rq1llm-%e5%b8%b8%e7%8a%af%e5%93%aa%e4%ba%9b%e9%94%99%e8%af%af">#</a>
</h3>
<p><strong>语义维度</strong>：最常见的是条件错误（缺失条件、条件写错）和逻辑方向错误。小模型更容易生成“垃圾代码”或漏掉关键步骤，大模型则倾向于在细节处翻车（常量取值错误、算术操作符写错）。大部分错误跨越多行，意味着简单的点修补往往救不了。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104145098.png" >
    </div>

    
</figure>
</p>
<p><strong>句法维度</strong>：错误高发于整块代码块、if/else、循环和函数调用。不同模型有自己的“弱项”：CodeGen-16B、InCoder-1.3B 更易把函数名写错；GPT-3.5、SantaCoder、StarCoder 更常犯参数错误。整体来看，定位错误位置只是第一步，同一个位置的根因可能截然不同。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104153166.png" >
    </div>

    
</figure>
</p>
<p>即使错误出现在相似的位置，其语义根因也可能千差万别，因此需要采用不同的修复方式。——定位只是第一步，真正修好还得看根因。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104736240.png" >
    </div>

    
</figure>
</p>
<p>一种语义特征，如常量值错误，可能出现在不同的位置。精确地定位此类错误可能具有挑战性。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104746298.png" >
    </div>

    
</figure>
</p>
<p>在语义层面，GPT-3.5 和 GPT-4 没有产生任何“无意义代码”片段，而另外四个模型都会出现。这很可能源于前两者训练数据规模巨大，使它们更有能力避开完全跑题或毫无作用的输出。</p>
<p>在句法层面，作者发现 CodeGen-16B 生成“错误代码块”的比例反而更小。这可能与它只用 Python 代码进行专门化训练有关：单一语言的深度学习，有助于减少大段语法结构性错误。而其他模型是在多语言代码语料上训练的，可能导致在具体语言（如 Python）上生成整段结构时更容易失手。</p>
<h3 class="heading" id="b-rq2修复这些错误要多大代价">
  B. RQ2：修复这些错误要多大代价？
  <a class="anchor" href="#b-rq2%e4%bf%ae%e5%a4%8d%e8%bf%99%e4%ba%9b%e9%94%99%e8%af%af%e8%a6%81%e5%a4%9a%e5%a4%a7%e4%bb%a3%e4%bb%b7">#</a>
</h3>
<ul>
<li>84.21% 的错误需要超过 50 次编辑，52.63% 超过 200 次；多数错误属于“多行/多块”级别。</li>
<li>CodeBERTScore 中位数约 0.2，语义偏差大。尤其中位数只有 0.05 的 GPT-3.5，一旦出错往往偏得更远：要么一次就写对，要么直接写成大片错误代码。</li>
<li>参考自动程序修复的粒度划分：InCoder-1.3B 的“多块错误”占比最高（41%），修复成本最吓人；SantaCoder 的单行错误最多（35%）。</li>
</ul>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104808880.png" >
    </div>

    
</figure>
</p>
<p>总体来看，文本相似度低 + 语义相似度低，与 RQ1 的发现一致：LLM 常犯的不是“小错”，而是“缺失多步”“逻辑方向错误”这类非平凡问题，修起来需要大量编辑。例如，“缺失多步”这类错误的中位编辑次数就达 108 次。</p>
<p>有趣的是，GPT-3.5 和 GPT-4 虽然整体性能最好，但一旦出错，偏差反而更大：它们的 Levenshtein 距离中位数比其他模型更高。这意味着它们通常要么对，要么一错就错成“大段代码块错误”，修复所需工作量反而更多。</p>
<p>作者借鉴自动程序修复（APR）领域的做法，把所有错误按修复粒度分成三类。</p>
<p>GPT-3.5 与 GPT-4 的三类错误分布更均衡；SantaCoder 的单行错误最多（35%）；StarCoder 的单块错误最多（57%）；InCoder-1.3B（准确率最低的模型）多块错误最多（41%），意味着它的错误往往散落在多处，修起来最麻烦。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104850566.png" >
    </div>

    
</figure>
</p>
<h3 class="heading" id="c-rq3任务复杂度如何影响表现">
  C. RQ3：任务复杂度如何影响表现？
  <a class="anchor" href="#c-rq3%e4%bb%bb%e5%8a%a1%e5%a4%8d%e6%9d%82%e5%ba%a6%e5%a6%82%e4%bd%95%e5%bd%b1%e5%93%8d%e8%a1%a8%e7%8e%b0">#</a>
</h3>
<p>作者用提示词长度、标准答案的 LOC、AST 节点数量作为复杂度代理。统计显示：</p>
<ul>
<li>对每个模型，“成功任务 vs 失败任务”在三项指标上都存在显著差异（p &lt; 0.05）。</li>
<li>提示超过 150 个词的失败案例中，64.0% 属于垃圾代码；标准答案 LOC 超过 12 行的失败案例中，55.9% 同样是垃圾代码。</li>
<li>复杂任务下，模型更容易在理解题意阶段就跑偏，连基本骨架都没搭出来。</li>
</ul>
<p>也就是说，对所有 6 个模型而言，“通过”的任务与“失败”的任务在两项复杂度代理指标上都存在显著统计差异（作者单独做了p 值检验）
失败的任务通常提示更长（描述文字更多、更复杂），标准解答行数更多，语法结构也更复杂（AST 节点更多）。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104907624.png" >
    </div>

    
</figure>
</p>
<p>进一步深入查看每个模型中“提示长度超过 150 个词”的失败任务。按之前的语义分类，这些失败里有 64.0% 属于“垃圾代码”——即与任务目标无关的无效代码。举例任务 129 的提示长达 249 词，要求在给定网格中找到长度为 k、路径和最小的路径。InCoder-1.3B 没理解复杂需求，只生成了一串毫无意义的 append 操作。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104951842.png" >
    </div>

    
</figure>
</p>
<p>在 LOC 维度上也出现类似模式：当标准答案超过 12 行代码时，失败的任务中有 55.9% 属于垃圾代码。比如任务 105 需要三步：排序（1–9）、反转、把每个数字换成对应的英文字符串。正确答案有 24 行代码，但 CodeGen-16B 没弄懂要求，只返回了一个空数组。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029104957386.png" >
    </div>

    
</figure>
</p>
<h3 class="heading" id="d-rq4测试通过率与错误模式">
  D. RQ4：测试通过率与错误模式
  <a class="anchor" href="#d-rq4%e6%b5%8b%e8%af%95%e9%80%9a%e8%bf%87%e7%8e%87%e4%b8%8e%e9%94%99%e8%af%af%e6%a8%a1%e5%bc%8f">#</a>
</h3>
<p>把没通过所有测试的代码细分为完全失败（所有用例都挂）和部分失败（只挂一部分用例），并排除了那 19 个“全通过但其实不等价”的特殊案例。</p>
<p>首先看语义特征。纯注释（only comments）和无意义代码（meaningless code）是最容易导致完全失败的两类根因。看似小问题的“未定义名称”（undefined name）也常常导致完全失败，因为一运行就异常崩溃。反而像“缺失多步”这种听起来很严重的错误，经常只是让模型漏掉部分需求，因此还能侥幸通过一些测试——说明测试用例不够强，或者模型并非完全误解题意。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029105005631.png" >
    </div>

    
</figure>
</p>
<p>举例：Task 125 需要在“字符串没有空格”的情况下按逗号分割；若也没有逗号，还要继续做别的处理。CodeGen-16B 只实现了按空格切分，后面步骤全漏，于是它只能通过包含空格的测试，用例里没空格时就挂了，属于“部分失败”。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029105038118.png" >
    </div>

    
</figure>
</p>
<p>还有一个意外发现是“逻辑方向错误”的代码也可能偶然通过几例测试。比如 Task 75，InCoder-1.3B 没按题意实现，但却能过 5、10、30 这些测试。合理推测是：提示里自带的测试样例给了模型“表层关联”，它记住了某些输入-输出组合，从而用不相关的逻辑碰巧命中部分用例。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029105050285.png" >
    </div>

    
</figure>
</p>
<p>再看句法特征。如果错误发生在 if 语句（if error），82% 是部分失败，18% 才是完全失败。原因是 if 错误往往只是误解了其中某个条件，其余代码可能仍然正确，所以能过掉一些用例。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029105105487.png" >
    </div>

    
</figure>
</p>
<p>比如 Task 0，SantaCoder 只考虑了列表中相邻元素，忽略了非相邻的情况，因此错过了那条特定测试，形成部分失败。</p>
<p>











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="" src="https://blogxiaozheng.oss-cn-beijing.aliyuncs.com/images/20251029105109359.png" >
    </div>

    
</figure>
</p>
<h2 class="heading" id="iv-discussion--future-work">
  IV. Discussion &amp; Future Work
  <a class="anchor" href="#iv-discussion--future-work">#</a>
</h2>
<ol>
<li>如何修复 LLM 生成的错误代码：</li>
</ol>
<p>作者指出：不同模型犯错的语义与句法特征差异巨大（Finding 1、2）。像 if 条件错误、函数参数错误这种单行或单点逻辑问题，传统自动程序修复（APR）技术已经比较擅长修复。但论文的发现也显示，大量错误其实是多行、多块的结构性问题。</p>
<p>为突破这一局限，近来有人用 LLM 本身来做“程序修复代理”（Program Repair Agents），依靠错误信息等粗粒度信号引导修复。本文贡献的细粒度分类（语义+句法）可以更精确地指导修复：先训练一个模型预测错误类型，再把预测结果嵌入提示词里引导修复代理。
例如，不再是笼统地说“修 Line 6 的 bug”，而是明确提示“修正第 6 行的函数参数错误”。</p>
<p>这里文章用 GPT-4 做了一个小实验验证：在 HumanEval 的 18 个错误里，如果加入他们的标签信息，GPT-4 能修好 7 个（不用标签时只修好了 4 个）；在更难的 BigCodeBench-Hard 上，带标签能修好 12 个，而不用标签只能修好 3 个。说明这套分类越在困难任务上越能发挥作用。</p>
<ol start="2">
<li>如何更精准地定位错误：</li>
</ol>
<p>找准“错在哪儿”是修复前的第一步，但 Finding 2 显示错误可能出现在各种结构里，定位并不容易。传统定位方法依赖高质量、覆盖全面的测试用例（谱系法等），构造这些用例很费力；深度学习式定位通常靠源代码特征和错误信息。但 LLM 生成代码还有更多可利用的信号：如每步解码的 logits、token 概率分布、自注意力分数等。未来可以探索把这些“生成过程信号”与错误消息、代码特征一起用来预测模型从哪一步开始跑偏。</p>
<ol start="3">
<li>如何估计代码正确性与任务上限：</li>
</ol>
<p>Finding 4 表明，当前 LLM 对复杂任务仍很吃力。这里有两类问题：</p>
<p>1）能否给定一个模型，估计它能处理的任务复杂度上限？论文里只用了提示长度、LOC 这类简单指标，后续可以考虑更精细的度量，以便准确评估模型能力边界，提高生成可靠性。</p>
<p>2）能否仅凭提示特征（如长度）来预测任务难度和最终代码是否正确？已有工作尝试让 LLM 直接当“评审员”，不依赖测试用例就判定代码是否正确（如 CodeJudge 在 HumanEval 上做到 73.13%，但在 BigCodeBench 上只有 54.56%）。这类技术若更成熟，可帮助开发者根据“正确性估计”分配审查与测试资源。</p>
<h2 class="heading" id="v-threats-to-validity">
  V. Threats to Validity
  <a class="anchor" href="#v-threats-to-validity">#</a>
</h2>
<ul>
<li><strong>内部效度</strong>：人工标注可能引入主观性；作者通过多轮共识与 κ 检验把不一致压到了 0.09 以内。</li>
<li><strong>外部效度</strong>：只覆盖 Python 函数级任务、单一数据集与温度设置；尚未验证到其它语言、任务类型或提示策略上的可推广性。</li>
<li><strong>模型范围</strong>：仅分析六个模型，且大模型样本受限。随着更强模型出现，错误分布可能会继续演化。</li>
</ul>

    </div>

    
    <section class="garden-comments">
      <script src="https://giscus.app/client.js"
        data-repo="Xiaozheng03Asada/Xiaozheng03Asada.github.io"
        data-repo-id="R_kgDOQBKVLg"
        data-category=""
        data-category-id="DIC_kwDOQBKVLs4Cwj23"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

    </section>
    
  </article>
</div>

      
    </main>
  </div>

  
  





    




  

  
  <link rel="stylesheet" 
  href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css">
  
<script defer 
  src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false }
      ]
    });
  });
</script>
  
</body>

<script src="/js/theme-switch.js"></script>
<script defer src="/js/copy-code.js"></script>
 
</html>
